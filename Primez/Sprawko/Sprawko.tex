\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lscape} 
\usepackage{lmodern}
\usepackage[svgnames]{xcolor}
\usepackage[a4paper,bindingoffset=0.2in,%
            left=0.5in,right=0.5in,top=0.5in,bottom=1in,%
            footskip=.25in]{geometry}
\pagenumbering{gobble}
\usepackage[colorlinks=true, linkcolor=Black, urlcolor=Blue]{hyperref}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\usepackage[svgnames]{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}


\begin{document}
\title{Sprawozdanie z zadania na Przetwarzanie Równoległe\\
\large Projekt 1\\
\large Sebastian Michoń 136770, Marcin Zatorski 136834}
\date{\vspace{-10ex}}
\maketitle

\section{Wstęp}
\begin {enumerate}
\item Sebastian Michoń 136770: grupa dziekańska L1 - grupa poniedziałkowa, 8:00
\item Marcin Zatorski 136834: grupa dziekańska L10 - grupa środowa, 13:30
\item Wymagany termin oddania sprawozdania: 27.04.2020r.
\item Rzeczywisty termin oddania sprawozdania: 27.04.2020r.
\item Wersja I sprawozdania
\item Adresy mailowe: sebastian.michon@student.put.poznan.pl, marcin.r.zatorski@student.put.poznan.pl
\item Celem realizowanego zadanie jest współbieżne wyznaczanie liczb pierwszych i badanie wydajności kodu w zależności od rozwiązania - domenowego i funkcyjnego.
\end {enumerate}

\section{Wykorzystywany system równoległy}
\begin {enumerate}
	\item Kompilator: icpc (Intel C++ compiler) 19.1.1.217
	\item Do zdobycia informacji na temat przetwarzania używałem Intel VTune'a
	\item System operacyjny: Ubuntu 18.04
	\item Procesor Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz - 4 rdzenie, 2 wątki na 1 rdzeń: 8 procesorów logicznych i 4 fizyczne. Do pomiarów został wyłączony HyperThreading, co za tym idzie używałem co najwyżej 4 procesorów logicznych. Linia pamięci podręcznej procesora ma 64 bajty. Pamięc cache ma: 
	\begin{enumerate}
		\item L1: 256 kilobajtów
		\item L2: 1024 kilobajty
		\item L3: 8192 kilobajty
	\end{enumerate}
	Pamięc L2 i L3 jest dostępna dla wszystkich procesorów, L1 jest lokalna dla procesora.
	
\end {enumerate}

\section{Używane oznaczenia}
\begin{enumerate}
	\item \(l\), \(r\) oznaczają kolejno lewy i prawy koniec przedziału, w którym mają zostać wyznaczone liczby pierwsze.
	\item \textbf{Domknięta część sita} to taka część elementów zrównoleglonego sita, w której liczby oznaczono jako pierwsze/złożone i do której nie zostanie dokonany zapis w trakcie wykonywania sita. W szczególności, aby wypełnić równolegle sito o rozmiarze \(n\), jego część domknięta musi zawierać wszystkie liczby z przedziału \(<0;\lfloor\sqrt{n}\rfloor>\).
	\item \textbf{Otwarta część sita} to taka część elementów zrównoleglonego sita, w której liczby nadal mogą zostać odznaczone jako złożone.
	\item W kodach jeśli res[\(i\)]==1 to \(i\) jest liczbą złożoną.
	\item Część kodów w sprawozdaniu została uproszczona względem oryginału - tutaj moim celem jest pokazanie koncepcji.
\end{enumerate}

\section{Użyte kody}
\begin {enumerate}
	\item 01\_erasto\_single.cpp - Kod sekwencyjny, standardowe sito erastotenesa działające w\\ \(O(r*loglog(r))\), z podwójną optymalizacją: do odznaczania liczb złożonych używane są tylko liczby pierwsze (np. nie używam 6, aby odznaczyć 36, 42.. etc., ponieważ te zostały już odznaczone przez każdy pierwszy dzielnik 6 - czyli 2 i 3), ponadto odsiew rozpoczyna się od kwadratu danej liczby - jest to poprawne, ponieważ jeśli liczba \(x\) nie jest pierwsza to jej najniższy dzielnik \(d>1\) spełnia \(d\le \sqrt{x}\).
	\begin{lstlisting}[style=mystyle, caption= Sito Erastotenesa][language=C]
	for (i=2;i*i<=n;i++){
		if (res[i]==0){
			for (j=i*i;j<=n;j+=i) res[j]=1;
		}
	}
	\end{lstlisting}
	Celem kodu jest jedynie pokazanie koncepcji; nie zachodzi wyścig ani nie ma synchronizacji, ponieważ jest jeden wątek.
	\item 02\_most\_primitive.cpp - Kod sekwencyjny, który szuka dzielnika \(d\) liczby \(x\) pośród liczb mniejszych równych jej pierwiastkowi: \(d \le \sqrt{x}\). Rozwiązanie to działa w złożoności \(O((r-l)*\sqrt{r})\). Sprawdzałem podzielność także dla liczb, które nie są pierwsze, aby nie używać żadnych tablic poza tablicą znalezionych liczb pierwszych - celem jest pokazanie kodu wykorzystującego w jak najmniejszym stopniu tablice, co za tym idzie mającego niewielkie narzuty związane z dostępem do pamięci.
	\begin{lstlisting}[style=mystyle, caption= Rozwiązanie pierwiastkowe][language=C]
	for (i=l;i<=r;i++){
		for (j=2;j*j<=i;j++){
			if (i%j==0) {
				res[i]=1;
				break;
			}
		}
	}
	\end{lstlisting}
	\item 03\_erasto\_functional\_static\_schedule.cpp - kod równoległy, koncepcja sita, podejście funkcyjne. Funkcja najpierw wyznacza rekursywnie wszystkie liczby pierwsze \(p\le \sqrt{n}\), gdzie \(n\) to docelowy rozmiar sita, następnie sama poszukuje liczb pierwszych \(p\le n\). Kluczowa część algorytmu wygląda tak:
	\begin{lstlisting}[style=mystyle, caption= Sito funkcyjne ze static schedulingiem][language=C]
	#pragma omp parallel for
	for (i=0;i<=sq;i++){
		if (res[i]==1) continue;
		int sv=sq+1;
		int j=sv-sv%i+((sv%i==0)?0:i);
		for (j=max(i*i, j); j<=n; j+=i) res[j]=1;
	}
	\end{lstlisting}
	Gdzie \(sq\) oznacza \(\lfloor(\sqrt{n})\rfloor\), a \(sv\) to najmniejsza liczba większa równa \(sq+1\) i \(i^2\) podzielna przez \(i\). Własności tego kodu:
	\begin{enumerate}
		\item Dyrektywa powyżej tworzy zbiór wątków, którym przydziela w przybliżeniu równy podzbiór części domkniętej sita; co istotne, przy tak sformułowanym kodzie wątek będzie wykonywał kolejne iteracje - na przykład 1. wątek może wykonać je dla i=2, 3, 5, 7, a 2. wątek dla 11, 13, 17, 19. Jest to nieefektywne, ponieważ procesy dostaną taką samą ilość liczb, którymi będą odsiewać liczby z otwartej części sita, a proces, który dostanie najmniejsze liczby wykona najwięcej operacji: w powyższym przypadku, 1. wątek wykona nieco mniej niż \(\frac{n}{2}+\frac{n}{3}+\frac{n}{5}+\frac{n}{7}\) operacji oznaczenia liczby (gdzie \(n\) to rozmiar sita - "nieco mniej" wynika z tego, że nie odznaczam liczb \(x<\sqrt{n})\)), a 2. wątek \(\frac{n}{11}+\frac{n}{13}+\frac{n}{17}+\frac{n}{19}\) - czyli dużo mniej.
		\item Nie zachodzi wyścig (rozumiany jako zależność działania programu od kolejności wykonywania wątków), ponieważ wątki modyfikują tylko część otwartą sita, ponadto jeśli zmieniam wartość jakiegoś elementu tablicy, w której zaznaczam liczby pierwsze, to mogę tylko oznaczyć liczbę jako złożoną; co za tym idzie, jeśli liczba zostanie oznaczona przez kilka wątków jako liczba złożona, to niezależnie od tego, który z nich oznaczy ją jako pierwszy, który później nie zajdzie wyścig. Nie zmieniam w pętli żadnej zmiennej globalnej poza tablicą pierwszości.
		\item Synchronizacja zachodzi tylko na końcu pętli for, nie powinna mieć istotnego wpływu na czas obliczeń - wywołania rekursywne wykonają się relatywnie szybko, bo suma rozmiarów sit, które będą w nich wypełniane jest nie większa niż \(2*\sqrt{n}\) - można to pokazać przez \(\sqrt[2]{n}+\sqrt[4]{n}+..+k\le\sqrt{n}+\frac{\sqrt{n}}{2}+\frac{\sqrt{n}}{4}+..+\frac{\sqrt{n}}{2^{\lfloor log_2(n) \rfloor}}\le 2*\sqrt{n}\), gdzie \(k \le 4\) - warunek początkowy rekursji, zaś czas wykonania całego sita i tak jest ograniczony przez czas wykonania najwolniejszego procesu w pierwszym wywołaniu funcji (nierekursywnym).
		\item False sharing może zajść, gdy aktualizuję liczbę znajdującą się w cache po modyfikacji zmiennej w pobliżu w tablicy pierwszości przez inny wątek. Taka sytuacja może zajść przez cały czas działania sita, ponieważ wszystkie wątki mogą aktualizować całą tablicę pierwszości; także w szczególnym przypadku, gdy sprawdzam pod kątem pierwszości liczbę \(x\) z części domkniętej sita, razem z nią ściągając do cache fragment części otwartej sita, ponieważ \(|x-\lfloor\sqrt{n}\rfloor|<64\) (64 bajty to rozmiar linii pamięci, a rozmiar typu bool na używanym sprzęcie to 1 bajt).
	\end{enumerate}
	\item 04\_erasto\_functional\_handmade\_scheduling.cpp - kod równoległy, koncepcja sita, podejście funkcyjne. Kod jest analogiczny do poprzedniego, ale iteracje są ręcznie przypisywane do każdego wątku - Najpierw wyliczam sumę \(sum=\frac{1}{2}+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+...+\frac{1}{np}\), gdzie \(np\) to najwyższa liczba pierwsza \(np\le\sqrt{n}\)  i średnią liczbę operacji zmniejszoną \(n\)-krotnie, które mają być wykonywane przez proces: \(partsum=\frac{sum}{proc}\), gdize \(proc\) to liczba procesów. Następnie każdemu procesowi przydzielam w osobnej tablicy liczby pierwsze, którymi będzie skreślał elementy tablicy w ten sposób, że:
	\begin{enumerate}
		\item \(i\)-ty proces dostanie \(i\)-tą liczbę pierwszą
		\item następnie proces będzie dobierał sobie nieprzydzielone liczby pierwsze począwszy od \(np\) do momentu, w którym jego szacowana liczba operacji nie przekroczy \(psum\)
	\end{enumerate}
	Kod odpowiadający za przydział liczb pierwszych do tablicy procesu:
	\begin{lstlisting}[style=mystyle, caption=  Ręczny scheduling sita funkcyjnego][language=C]
	for (i=0;i<=sq;i++){
		if (res[i]==0) summa+=1.0/i;
	}
	part=summa/proc;
	
	int beg=0, end=sq;
	double partsum=0;
	for (i=0;i<proc;i++){
		ij[i]=0;
		partsum=0;
		for (j=beg;j<=end;j++){
			if (res[j]==0) {
				squarez[i][ij[i]]=j, partsum+=1.0/j, ij[i]++;
				break;
			}
		}
		beg=j+1;
		if (partsum<part){
			for (j=end;j>=beg;j--){
				if (res[j]==0) {
					squarez[i][ij[i]]=j, partsum+=1.0/j, ij[i]++;
				}
				if (partsum>=part) break;
			}
			end=j-1;
		}
	}
	\end{lstlisting}
	Dzięki powyższemu rozwiążę problem przedstawiony w części (a) poprzedniego rozwiązania - procesy będą względnie równo dzielić się pracą bez dodatkowego narzutu związanego z synchronizacją, przy czym procesy, które wezmą najniższe liczby pierwsze (2, 3, czasem 5) nadal wykonałyby największą pracę, ponieważ dla \(n<500000000 \land proc=8\) nadal zachodzi \(\frac{1}{2}\ge psum)\) - Analogicznie dla 3. Problemem z tą heurystyką jest nieuwzględnienie cache missów: odznaczanie liczb złożonych za pomocą liczby 2 będzie miało dużo rzadziej cache missa niż odznacznie liczb złożonych za pomocą za pomocą liczby 8387, a następnie kolejnych 10 liczb pierwszych, za każdym razem wymieniając dane w cache. Pozostałe części rozwiązania - (b), (c), (d) są identyczne dla tego kodu.
	\item 05\_erasto\_functional\_dynamic\_schedule.cpp - działa tak jak kod (3), ale używa innej dyrektywy:
	\begin{lstlisting}[style=mystyle, caption= Sito funkcyjne z dynamic schedulingiem][language=C]
	#pragma omp parallel for schedule(dynamic)
		for (i=0;i<=sq;i++){
			if (res[i]==1) continue;
			for (int j=i*i; j<=n; j+=i) res[j]=1;
		}
	\end{lstlisting}
	Dzięki zmianie dyrektywy na schedule(dynamic) wątek po zakończeniu swojej pracy wykonuje część (blok) pracy innego wątku zamiast niego - dzięki temu wątki będą się dzieliły równo pracą, natomiast w porównaniu z kodem (3) dojdzie narzut związany z koniecznością synchronizacji wątków. Rozwiązanie zadania (3) używało domyślnej klauzuli schedule(static).
	\item 07\_erasto\_domain.cpp - kod równoległy, koncepcja sita, podejście domenowe. Każdy wątek, znając swój numer, używając całej tablicy pierwszości do \(\sqrt{n}\) włącznie oznacza wszystkie liczby podzielne przez daną liczbę pierwszą większe niż \(\sqrt{n}\), które należą do przedziału unikalnego dla danego procesu, wyznaczonego za pomocą jego numeru.
	\begin{lstlisting}[style=mystyle, caption= Sito funkcyjne z dynamic schedulingiem][language=C]
	#pragma omp parallel
	{
		int left=(n/thr)*omp_get_thread_num(), i, j, based_left;
		int right=left+n/thr-1;
		if (omp_get_thread_num()==thr-1) right=n;
		if (left<=sq) left=sq+1;
		
		for (i=0;i<=sq;i++){
			if (res[i]==0){
				based_left=left-left%i+((left%i==0)?0:i);
				for (j=based_left;j<=right;j+=i) res[j]=1;
			}
		}
	}
	\end{lstlisting}
	Kod ten ma 3 zasadnicze różnice w porównaniu z kodem (3) w kontekście wspólbieżności:
	\begin{enumerate}
		\item Dyrektywa tworzy wątki, które podzielą się nieomal równomiernie pracą - ponieważ każdy wątek musi użyć każdej liczby pierwszej z części domkniętej sita do oznaczenia przedziału z części otwartej sita o wielkości (prawie) równej dla każdego wątku.
		\item False sharing zachodzi w szczególnym przypadku, gdy sprawdzam pod kątem pierwszości liczbę \(x\) - albo ją odnaczam jako złożoną, razem z nią ściągając do cache liczbę \(y\) w części otwartej używanej przez inny wątek, która może się zmieniać, ponieważ \(|x-y|<64\) (64 bajty to rozmiar linii pamięci, a rozmiar typu bool na systemie, na którym zaszło testowanie to 1 bajt). Może on jednak zajść nie więcej niż \((4+1)*64*log_2(n)\) razy, bo \(\sqrt[log_2(n)]{n}\le log_2(n)\), a liczba wątków to co najwyżej \(4\), dodatkowe \(+1\) wynika z wątku używającego podciągu obok tablicy z części domkniętej sita - jest to liczba o kilka rzędów wielkości mniejsza niż \(n\), zatem (co pokaże później VTune profiler) false sharing nie będzie prawie wcale wpływał na czas przetwarzania.
		\item Wątki będą modyfikowały współdzielone L2 i L3 cache - co za tym idzie, często będą zachodziły cache-missy, ponieważ L2 i L3 cache będą często zmieniały dane - w praktyce każdy wątek będzie modyfikował zupełnie inne części tablicy, które będą stale się zmieniać (inaczej niż np. w przypadku, w którym 1 wątek modyfikuje co 2. element tablicy), a nie zmieszczą się one w L1 cache (mogącej pomieścić 32KB danych).
	\end{enumerate}

	\item 08\_erasto\_super\_domain.cpp - usunięty został problem częstych cache missów przez to, że wątek aktualizuje w 1 pętli co najwyżej 32000 kolejne elementy sita plus kilka dodatkowych; W moim algorytmie utrzymuję tablicę liczb pierwszych modyfikowaną przed stworzeniem wątków wartościami \(x\le \sqrt{n}\); Każdy wątek aktualizuje kolejne liczby pierwsze od poprzedniej oznaczonej albo startowej, dopóki nie przekroczy \(left+32000\) albo prawej granicy podzbioru, który wolno mi modyfikować. (\(left\) to początek iteracji), wtedy jest to jego ostatnia iteracja w tym batchu; przechodzę do kolejnej liczby powtarzając proces; w końcu, po przejściu całej tablicy liczb pierwszych, wracam do 1. liczby pierwszej i aktualizuje \(left+=32000\). Powtarzam proces dopóki każda liczba pierwsza nie przekroczy prawej granicy zadanego ciągu.
	\begin{lstlisting}[style=mystyle, caption= Sito funkcyjne z dynamic schedulingiem][language=C]
	ineo=0;
	for (int vi=0;vi<=sq;vi++){
		if (res[vi]==0) {
			for (ite=0;ite<10;ite++) dp[ite][vi]=0;
			neoprimez[ineo]=vi, ineo++;
		}
	}
	
	#pragma omp parallel
	{
		int thnum=omp_get_thread_num(), allth=omp_get_num_threads();
		int left=a+((n-a)/allth)*thnum, i, ji, j, finished=0, curfun=left;
		int right=left+(n-a)/allth-1;
		if (thnum==allth-1) right=n;
		if (left<=sq) left=sq+1;
		
		while (finished<ineo){
			curfun=curfun+outer;
			for (ji=0;ji<ineo;ji++){
				i=neoprimez[ji];
				if (dp[thnum][i]==0) dp[thnum][i]=max(modal(left, i), modal(a, i));
				for (j=dp[thnum][i]; j<=right;j+=i){
					if (j>=curfun) break;
					p[j]=1;	
				}
				if (j>right) finished++;
				dp[thnum][i]=j;
			}
		}
	}
\end{lstlisting}
Jedyną fundamentalną różnicą pomiędzy tym kodem a zwykłym sitem domenowym jest unikanie cache missów i dążenie do trzymania w L1 cache jak największej części aktualnie używanego sita. Poza tym złożoność może się zwiększyć, a przynajmniej nie jestem w stanie dowieść standardowej złożoności sita. To rozwiązanie pozwala efektywnie zrównoleglić zadanie uzyskując CPI=0.331 i czas przetwarzania 0.4s dla \(l=1, r=10^9\) na 4 rdzeniach, co pokażą wyniki VTune'a.

	\item 09\_sqrt\_domain.cpp - kod równoległy, koncepcja dzielenia, podejście domenowe (dodatkowy kod do pokazania współbieżności bez dzielenia pamięci). Każdy wątek używa liczb \(y\le\sqrt{n}\) do odznaczania własnego podzbioru \(N\) wyznaczanego przez dyrektywę \#pragma omp parallel for
	\begin{lstlisting}[style=mystyle, caption= Sito funkcyjne z dynamic schedulingiem][language=C]
	#pragma omp parallel for
	for (i=2;i<=n;i++){
		for (int j=2;j*j<=i;j++){
			if (i%j==0) {
				res[i]=1;
				break;
			}
		}
	}
	\end{lstlisting}
	Własności tego kodu:
	\begin{enumerate}
		\item Wszystkie wątki dostaną względnie równy podzbiór zbioru liczb do sprawdzenia o podobnym rozkładzie najniższych dzielników.
		\item W kodzie tym nie zachodzą wyścigi, ponieważ każdy wątek szuka dzielników innych liczb (i ewentualnie oznacza je jako pierwsze - jest to jedyna modyfikacja współdzielonej zmiennej przez wątek).
		\item Jedyna synchronizacja zajdzie na końcu pętli for.
		\item False sharing może zachodzić tylko na stykach podzbiorów zbioru otwartego modyfikowanych przez 2 wątki.
	\end{enumerate}
	Kod ten się bardzo efektywnie zrównolegla, ale i tak jest wiele wolniejszy od sit z powodu gorszej złożoności obliczeniowej.
\end {enumerate}

\section {Wprowadzenie do rezultatów pomiarów}
\begin{enumerate}
	\item Wykonałem 3 eksperymenty z kodem:
	\begin{enumerate}
		\item Pierwszym było stworzenie podstawowego sita i rozwiązania pierwisatkowego. Rozwiązanie pierwiastkowe pokazałem od razu w wersji zrównoleglonej, jej konstrukcja ograniczała się bowiem do dodania jednej dyrektywy do kodu sekwencyjnego. Sito erastotenesa sekwencyjne było podstawą do dalszych obliczeń.
		\item Drugi eksperyment to sprawdzenie, jak w zależności od przydziału zadań i synchronizacji procesy używające sita w ramach koncepcji funkcyjnej będą działały, co będzie je ograniczało i które będzie efektywniejsze - ręcznie napisane, używające prostej heurystyki czy używające dyrektywy z dynamicznym przydziałem procesów do zadań.
		\item Trzecim, kluczowym eksperymentem było pokazanie, jak uzyskać eleganckie, bardzo szybkie sito w wariancie domenowym wykorzystując dobrodziejstwa Cache L1, jej własności i proste ulepszenie sita pod kątem zwiększenia liczby trafień do pamięci. Porównywałem je ze standardowym sitem domenowym.
	\end{enumerate}

	\item VTune Profiler używa licznika zdarzeń sprzętowych do zdobycia informacji na temat przetwarzania, po czym (po przetwarzaniu) łączy te informacje w metryki np. CPI. Używa do zdobywania informacji PMU (performance monitoring unit) - ich liczba jest ograniczona, a sumują one informację o jednym, konkretnym zdarzeniu, przez co część zdarzeń jest raczej estymowana niż deterministycznie obliczana. Pojedynczy PMU wyliczający jakąś konkretną statystykę, wiedząc o zajściu zdarzenia inkrementuje rejestr; gdy rejestr przyjmie wartość progu próbkowania, jest on łączony z instrukcją tak, aby dowiedzieć się, po ilu zdarzeniach globalnych zaszło tyle zdarzeń danego typu (co istotne, aby statystyka/estymacja była zasadna, musi zajść odpowiednia liczba zdarzeń globalnych). Metryki, które zostały użyte w tym sprawozdaniu, to: 
	
	\begin{enumerate}
		\item Clockticks - Liczba cykli procesora w trakcie przetwarzania.
		\item Instructions retired - liczba przedziałów alokacji, które zostały zatwierdzone i w pełni wykonane.
		\item Retiring - procent przedziałów alokacji, które zostały użyte (nie zaszło ograniczenie front-endu ani back-endu) i wykonane (nie zaszła błędna spekulacja).
		
		\item Front-end bound - ile procent przedziałów alokacji nie zostało wykorzystanych przez ograniczenie części wejściowej procesora, albo inaczej: jak często back-end mógł przyjąć jakąś instrukcję, ale nie otrzymał jej od front-endu. Front-end odpowiada za przyniesienie instrukcji (fetch), zdekodowanie jej i przekazanie do back-endu.
		
		\item Back-end bound - ile procent przedziałów alokacji nie zostało wykorzystanych przez ograniczenie części wyjściowej procesora, albo incaczej: jak często back-end nie przyjmuje instrukcji od front-endu, ponieważ nie ma zasobów na ich przetworzenie. Składają się na to: Core Bound i Memory bound.
		\item Memory bound - ile procent przedziałów alokacji mogło nie zostać wykonane przez zapotrzebowanie na załadowanie albo składowanie instrukcji - czyli narzut związany z dostępem do pamięci, której albo nie ma w cache, albo jest zabrudzona.
		\item Core bound - ile procent przedziałów alokacji mogło nie zostać wykonane przez ograniczenia inne niż te związane z pamięcią - między innymi dzielenie czy operacje arytmetyczne na liczbach zmiennoprzecinkowych.
		\item Effective physical core utilization - ile procent fizycznych rdzeni średnio było używanych w trakcie przetwarzania.
		\item Metryki L1, L2, L3 bound, a także DRAM bound - procentowe dane, w ilu cyklach procesora zaszła sytuacja, w której program mimo posiadania odpowiednich danych w cache/DRAMie nie mógł przyjąć operacji.
	\end{enumerate}
	Wykorzystywanym trybem pracy było Microarchitecture Exploration.
\end{enumerate}

\section{Tablica wynków: kody sit i pierwiastkowe}
Oznaczenia i skróty:
\begin{enumerate}
	\item name - nazwa kodu, pierwsz cyfry jego nazwy i skrót.
	\item left, right - przedział, dla którego wykonano program.
	\item T - liczba wątków
	\item Elapsed - czas, który upłynął od początku przetwarzania
	\item Ticks - liczba cykli procesora w trakcie wykonywania kodu.
	\item IR - Instructions Retired
	\item R - Retired
	\item FEB, BEB - Front-end bound, Back-end Bound
	\item MB, CB - Memory Bound,  Core Bound
	\item L1, L2, L3 - L1 Bound, L2 Bound, L3 Bound
	\item DRB, DTB - DRAM Bound, DTLB Store Overhead
	\item ECPU - Effective CPU Utilization
	\item Div - przyspieszenie przetwarzania równoległego
	\item Eff - efektywność przetwarzania równoległego
	\item Avg - liczba przetestowanych liczb w jednostce czasu.
\end{enumerate}
\begin{flushleft}
\begin{landscape}
	
	\resizebox{\columnwidth}{!}{%
	\begin{tabular}{| l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l | l |}
		\hline
		name & left & right & T & Elapsed & Ticks & IR & R & FEB & BEB & MB & CB & L1 & L2 & L3 & DRB & DTB & ECPU & Div & Eff & Avg \\ \hline
		03\_efss & 2.0 & 1.00E+09 & 4.0 & 10.199 & 6.08E+10 & 1.60E+10 & 6.8 & 0.4 & 92.4 & 75.5 & 16.9 & 9.7 & 0.3 & 17.5 & 0.0 & 36.3 & 34.3 & 728.5 & 182.12 & 9.80E+07 \\ \hline
		04\_efhs & 2.0 & 1.00E+09 & 4.0 & 8.802 & 1.20E+11 & 1.43E+10 & 2.8 & 0.9 & 96.1 & 78.7 & 17.4 & 0.0 & 0.0 & 35.5 & 0.0 & 43.2 & 80.5 & 628.71 & 157.18 & 1.14E+08 \\ \hline
		05\_efds & 2.0 & 1.00E+09 & 4.0 & 6.417 & 1.03E+11 & 1.47E+10 & 3.3 & 0.9 & 95.5 & 78.5 & 17.0 & 2.7 & 0.0 & 25.5 & 0.0 & 40.8 & 96.0 & 458.36 & 114.59 & 1.56E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+09 & 4.0 & 0.419 & 6.47E+09 & 1.81E+10 & 47.2 & 9.1 & 33.1 & 19.5 & 13.6 & 14.6 & 0.4 & 1.1 & 0.0 & 0.7 & 92.5 & 29.93 & 7.48 & 2.39E+09 \\ \hline
		07\_ed & 2.0 & 1.00E+09 & 4.0 & 9.204 & 1.47E+11 & 2.11E+10 & 3.9 & 0.6 & 95.3 & 73.3 & 22.1 & 6.5 & 0.0 & 24.5 & 0.0 & 35.6 & 94.8 & 657.43 & 164.36 & 1.09E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+09 & 1.0 & 1.494 & 6.30E+09 & 1.79E+10 & 49.8 & 14.8 & 25.1 & 21.5 & 3.6 & 26.4 & 2.0 & 1.4 & 0.0 & 1.7 & 24.2 & 106.71 & 106.71 & 6.69E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+09 & 2.0 & 0.769 & 6.33E+09 & 1.79E+10 & 49.4 & 12.0 & 28.8 & 20.2 & 8.7 & 19.5 & 0.9 & 1.1 & 0.0 & 1.2 & 47.4 & 54.93 & 27.46 & 1.30E+09 \\ \hline
		08\_esd & 2.0 & 1.00E+09 & 4.0 & 0.412 & 6.35E+09 & 1.79E+10 & 51.7 & 9.7 & 28.1 & 17.0 & 11.1 & 15.4 & 0.7 & 0.0 & 0.7 & 0.7 & 92.4 & 29.43 & 7.36 & 2.43E+09 \\ \hline
		07\_ed & 2.0 & 1.00E+09 & 1.0 & 11.113 & 4.72E+10 & 1.91E+10 & 8.9 & 0.8 & 90.1 & 72.5 & 17.6 & 21.2 & 0.9 & 0.0 & 9.9 & 33.3 & 24.2 & 793.79 & 793.79 & 9.00E+07 \\ \hline
		07\_ed & 2.0 & 1.00E+09 & 2.0 & 9.315 & 7.88E+10 & 1.92E+10 & 5.8 & 0.4 & 93.5 & 73.4 & 20.1 & 22.4 & 0.3 & 7.6 & 0.0 & 33.0 & 48.4 & 665.36 & 332.68 & 1.07E+08 \\ \hline
		07\_ed & 2.0 & 1.00E+09 & 4.0 & 9.266 & 1.48E+11 & 2.11E+10 & 4.1 & 0.7 & 95.0 & 72.7 & 22.3 & 7.6 & 0.0 & 23.4 & 0.0 & 34.6 & 94.8 & 661.86 & 165.46 & 1.08E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+07 & 1.0 & 0.019 & 4.80E+07 & 1.60E+08 & 0.0 & 20.8 & 79.2 & 79.2 & 0.0 & 41.7 & 0.0 & 0.0 & 0.0 & 0.0 & 23.2 & 1.36 & 1.36 & 5.26E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+07 & 2.0 & 0.014 & 5.60E+07 & 1.64E+08 & 0.0 & 0.0 & 100.0 & 0.0 & 100.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 34.9 & 1.0 & 0.5 & 7.14E+08 \\ \hline
		08\_esd & 2.0 & 1.00E+07 & 4.0 & 0.014 & 6.40E+07 & 1.68E+08 & 0.0 & 0.0 & 100.0 & 0.0 & 100.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 53.0 & 1.0 & 0.25 & 7.14E+08 \\ \hline
		07\_ed & 2.0 & 1.00E+07 & 1.0 & 0.053 & 1.72E+08 & 1.80E+08 & 0.0 & 0.0 & 100.0 & 92.9 & 7.1 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 23.7 & 3.79 & 3.79 & 1.89E+08 \\ \hline
		07\_ed & 2.0 & 1.00E+07 & 2.0 & 0.037 & 2.16E+08 & 2.00E+08 & 0.0 & 0.0 & 100.0 & 100.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 41.6 & 2.64 & 1.32 & 2.70E+08 \\ \hline
		07\_ed & 2.0 & 1.00E+07 & 4.0 & 0.025 & 2.52E+08 & 2.08E+08 & 0.0 & 0.0 & 100.0 & 0.0 & 100.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 75.1 & 1.79 & 0.45 & 4.00E+08 \\ \hline
		01\_es & 2.0 & 1.00E+09 & 1.0 & 10.429 & 4.43E+10 & 1.36E+10 & 7.1 & 0.5 & 92.2 & 77.0 & 15.3 & 18.2 & 1.5 & 1.1 & 7.9 & 32.1 & 24.2 & 744.93 & 744.93 & 9.59E+07 \\ \hline
	\end{tabular}
}
\end{landscape}
\end{flushleft}

\section{Wnioski}
\begin{enumerate}
	\item Rozwiązanie oparte na wyznaczaniu dzielników mniejszych równych od \(\sqrt{n}\) bardzo efektywnie się zrównolegla - procesy dzielą się pracą bardzo równo, przez większość czasu działania programu wykonuje się 7-8 wątków. Zwiększenie liczby procesów \(k\)-krotnie powoduje zmniejszenie czasu przetwarzania prawie \(k\)-krotnie, przy założeniu, że nowy wątek jest wykonywany przez inny procesor logiczny. Nie zachodzi prawie wcale False Sharing, ponieważ jedyna współdzielona zmienna to tablica liczb pierwszych. Wątki nie czytają współdzielonej pamięci, co powoduje, że praktycznie nie zachodzą cache missy. Wąskim gardłem rozwiązania jest Front-End Bound - co oznacza, że są większe problemy z dostarczeniem zadania do wykonania do Back-endu niż z jego wykonaniem; a także intensywne dzielenie, zwiększające Core-Bound. Algorytm pomimo zrównoleglenia nadal jest wolniejszy od sita, ponieważ ma większą złożoność - dla \(n=10^9\) ponad 1000-krotnie wolniejszy.
	\item Sito erastotenesa w podejściu funkcyjnym było w stanie uzyskać prawie 2-krotne przyspieszenie względem sekwencyjnego sita używając dynamic schedulingu. Co ciekawe, rozwiązania używające handmade schedulingu jest około 1.5 razy wolniejsze od rozwiązania używającego static schedulingu, pomimo tego, że ma prawie dwukrotnie wyższy współczynnik "effective physcial core utilization" - powodem jest to, że bardzo często zachodzi
	
	\item W podejściu 
\end{enumerate}

\end{document}
